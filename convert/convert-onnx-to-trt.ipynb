{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import requests\n\nfile_url = \"https://huggingface.co/datasets/nhotin/segment-text/resolve/main/model.onnx\"\nfile_path = \"model.onnx\"  \nresponse = requests.get(file_url, stream=True)\nif response.status_code == 200:\n    with open(file_path, \"wb\") as f:\n        for chunk in response.iter_content(chunk_size=1024):\n            f.write(chunk)\n    print(f\"Đã tải file ONNX thành công: {file_path}\")\nelse:\n    print(f\"Lỗi khi tải file: {response.status_code}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:55:08.067409Z","iopub.execute_input":"2025-03-19T12:55:08.067702Z","iopub.status.idle":"2025-03-19T12:55:14.494864Z","shell.execute_reply.started":"2025-03-19T12:55:08.067672Z","shell.execute_reply":"2025-03-19T12:55:14.493911Z"}},"outputs":[{"name":"stdout","text":"Đã tải file ONNX thành công: model.onnx\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install numpy onnx\n!pip install tensorrt==10.7.0\n!pip install pycuda","metadata":{"_uuid":"0646f729-f5bf-4414-b2a7-00a9d2eb2e22","_cell_guid":"5652b2e4-062b-4803-99f7-c0afd33a089e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-19T12:55:14.495868Z","iopub.execute_input":"2025-03-19T12:55:14.496187Z","iopub.status.idle":"2025-03-19T12:55:24.563083Z","shell.execute_reply.started":"2025-03-19T12:55:14.496152Z","shell.execute_reply":"2025-03-19T12:55:24.562224Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\nRequirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.17.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: tensorrt==10.7.0 in /usr/local/lib/python3.10/dist-packages (10.7.0)\nRequirement already satisfied: tensorrt-cu12==10.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorrt==10.7.0) (10.7.0)\nRequirement already satisfied: pycuda in /usr/local/lib/python3.10/dist-packages (2025.1)\nRequirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.10/dist-packages (from pycuda) (2025.1.1)\nRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (4.3.6)\nRequirement already satisfied: mako in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.3.9)\nRequirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (3.0.2)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import onnx\nimport os\nimport tensorrt as trt\nimport pycuda.driver as cuda\nimport pycuda.autoinit\nimport time\nimport numpy as np\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"","metadata":{"_uuid":"cc21678c-b22c-4808-af36-7254293f399c","_cell_guid":"db2f48da-a4cf-4cd3-9b98-ecff817c6a3e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-19T12:57:13.099914Z","iopub.execute_input":"2025-03-19T12:57:13.100422Z","iopub.status.idle":"2025-03-19T12:57:13.104717Z","shell.execute_reply.started":"2025-03-19T12:57:13.100395Z","shell.execute_reply":"2025-03-19T12:57:13.103916Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def check_tensorrt():\n    try:\n        print(f\"TensorRT version: {trt.__version__}\")\n        print(f\"CUDA version: {os.popen('nvcc --version').read().strip()}\")\n    except ModuleNotFoundError:\n        print(\"TensorRT chưa được cài\")\n\ncheck_tensorrt()","metadata":{"_uuid":"f6905140-100c-4f10-95e9-792ba97dfc9b","_cell_guid":"49878bc3-cace-44ab-ad3f-526b6eb4299b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-19T12:55:24.800383Z","iopub.execute_input":"2025-03-19T12:55:24.800821Z","iopub.status.idle":"2025-03-19T12:55:24.809401Z","shell.execute_reply.started":"2025-03-19T12:55:24.800768Z","shell.execute_reply":"2025-03-19T12:55:24.808602Z"}},"outputs":[{"name":"stdout","text":"TensorRT version: 10.7.0\nCUDA version: nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2023 NVIDIA Corporation\nBuilt on Tue_Aug_15_22:02:13_PDT_2023\nCuda compilation tools, release 12.2, V12.2.140\nBuild cuda_12.2.r12.2/compiler.33191640_0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def check_onnx_model(onnx_path):\n    model = onnx.load(onnx_path)\n    print(f\"Model name: {model.graph.name}\")\n\n    for input_tensor in model.graph.input:\n        dtype = onnx.TensorProto.DataType.Name(input_tensor.type.tensor_type.elem_type)\n        print(f\"Input: {input_tensor.name}, Type: {dtype}\")\n        \n    for output_tensor in model.graph.output:\n        dtype = onnx.TensorProto.DataType.Name(output_tensor.type.tensor_type.elem_type)\n        print(f\"Output: {output_tensor.name}, Type: {dtype}\")\n\nonnx_path = \"/kaggle/working/model.onnx\"\ncheck_onnx_model(onnx_path)","metadata":{"_uuid":"a49101d0-eebd-42df-894b-fd0317d23bb9","_cell_guid":"250efd25-2431-4e5c-8e53-2e3f1c3f5b0b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-19T12:55:24.810419Z","iopub.execute_input":"2025-03-19T12:55:24.810668Z","iopub.status.idle":"2025-03-19T12:55:25.758597Z","shell.execute_reply.started":"2025-03-19T12:55:24.810636Z","shell.execute_reply":"2025-03-19T12:55:25.757728Z"}},"outputs":[{"name":"stdout","text":"Model name: main_graph\nInput: input_ids, Type: INT32\nInput: attention_mask, Type: FLOAT16\nOutput: logits, Type: FLOAT16\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# import tensorrt as trt\n\n# def build_engine(onnx_file_path, engine_file_path, dynamic_shape=True, fp16=True):\n#     TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n#     builder = trt.Builder(TRT_LOGGER)\n#     network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n#     parser = trt.OnnxParser(network, TRT_LOGGER)\n\n#     # Đọc mô hình ONNX\n#     with open(onnx_file_path, 'rb') as model:\n#         if not parser.parse(model.read()):\n#             print('Lỗi: Không thể parse file ONNX')\n#             for error in range(parser.num_errors):\n#                 print(parser.get_error(error))\n#             return None\n\n#     config = builder.create_builder_config()\n#     config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)  # 1GB workspace\n\n#     if fp16 and builder.platform_has_fast_fp16:\n#         config.set_flag(trt.BuilderFlag.FP16)\n#         print(\"Đang sử dụng FP16 để tăng tốc\")\n\n#     if dynamic_shape:\n#         profile = builder.create_optimization_profile()\n#         # Thêm dynamic shape cho cả input_ids và attention_mask\n#         profile.set_shape(\"input_ids\", (1, 16), (1, 128), (1, 512))  # min, opt, max\n#         profile.set_shape(\"attention_mask\", (1, 16), (1, 128), (1, 512))  # min, opt, max\n#         config.add_optimization_profile(profile)\n#         print(\"Hỗ trợ Dynamic Shape cho `input_ids` và `attention_mask`!\")\n\n#     engine = builder.build_serialized_network(network, config)\n\n#     if engine is None:\n#         print(\"Lỗi: Không thể build engine TensorRT.\")\n#         return None\n\n#     with open(engine_file_path, 'wb') as f:\n#         f.write(engine)\n\n#     print(f\"Model converted successfully! Saved as {engine_file_path}\")\n#     return engine\n\n# engine_model = \"model.engine\"\n# build_engine(onnx_path, engine_model, dynamic_shape=True, fp16=True)\n\ndef build_engine(onnx_file_path, engine_file_path, dynamic_shape=True, fp16=True):\n    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n    builder = trt.Builder(TRT_LOGGER)\n    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n    parser = trt.OnnxParser(network, TRT_LOGGER)\n\n    with open(onnx_file_path, 'rb') as model:\n        if not parser.parse(model.read()):\n            print('Lỗi: Không thể parse file ONNX')\n            for error in range(parser.num_errors):\n                print(parser.get_error(error))\n            return None\n\n    config = builder.create_builder_config()\n    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)  # 1GB workspace\n\n    config.set_flag(trt.BuilderFlag.GPU_FALLBACK)\n\n    if fp16 and builder.platform_has_fast_fp16:\n        config.set_flag(trt.BuilderFlag.FP16)\n        print(\"FP16\")\n\n    if dynamic_shape:\n        profile = builder.create_optimization_profile()\n        profile.set_shape(\"input_ids\", (1, 16), (1, 128), (1, 512))  # min, opt, max\n        profile.set_shape(\"attention_mask\", (1, 16), (1, 128), (1, 512))  # min, opt, max\n        config.add_optimization_profile(profile)\n        print(\"Hỗ trợ Dynamic Shape!\")\n\n    engine = builder.build_serialized_network(network, config)\n    if engine is None:\n        print(\"Lỗi: Không thể build engine TensorRT.\")\n        return None\n\n    with open(engine_file_path, 'wb') as f:\n        f.write(engine)\n\n    print(f\"Model converted successfully! Saved as {engine_file_path}\")\n    return engine\n\nengine_model = \"model.engine\"\nbuild_engine(onnx_path, engine_model, dynamic_shape=True, fp16=True)\n","metadata":{"_uuid":"d7850156-3b08-42c1-bb2f-161c33cf32e1","_cell_guid":"bfde0c87-584c-43b5-864b-4cbc87babbdc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-19T12:57:41.023632Z","iopub.execute_input":"2025-03-19T12:57:41.023982Z","iopub.status.idle":"2025-03-19T12:58:11.402684Z","shell.execute_reply.started":"2025-03-19T12:57:41.023952Z","shell.execute_reply":"2025-03-19T12:58:11.401407Z"}},"outputs":[{"name":"stdout","text":"FP16\nHỗ trợ Dynamic Shape!\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-835620b63694>\u001b[0m in \u001b[0;36m<cell line: 88>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mengine_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model.engine\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mbuild_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-835620b63694>\u001b[0m in \u001b[0;36mbuild_engine\u001b[0;34m(onnx_file_path, engine_file_path, dynamic_shape, fp16)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hỗ trợ Dynamic Shape!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_serialized_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Lỗi: Không thể build engine TensorRT.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"def load_engine(engine_path):\n    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n        engine = runtime.deserialize_cuda_engine(f.read())\n    return engine\n\nengine = load_engine(\"model.engine\")\nprint(\"TensorRT Engine đã load thành công!\")","metadata":{"_uuid":"80fc7ed3-7582-493d-b3f6-fd9683347f5a","_cell_guid":"02beafff-6050-4386-9df4-f63060e7dd66","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-19T12:55:28.730151Z","iopub.status.idle":"2025-03-19T12:55:28.730394Z","shell.execute_reply":"2025-03-19T12:55:28.730296Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def benchmark_inference(engine, input_shape=(1, 128)):  \n    context = engine.create_execution_context()\n\n    input_data = np.random.randint(0, 100, size=input_shape).astype(np.int32)\n    attention_mask = np.ones(input_shape, dtype=np.int32)  # Giữ nguyên attention mask = 1\n\n    d_input = cuda.mem_alloc(input_data.nbytes)\n    d_mask = cuda.mem_alloc(attention_mask.nbytes)\n    d_output = cuda.mem_alloc(input_data.nbytes)  # Output có cùng shape với input\n\n    bindings = [int(d_input), int(d_mask), int(d_output)]\n\n    cuda.memcpy_htod(d_input, input_data)\n    cuda.memcpy_htod(d_mask, attention_mask)\n\n    start_time = time.time()\n    context.execute_v2(bindings)\n    end_time = time.time()\n\n    print(f\"Inference time: {end_time - start_time:.6f} s\")\n\nbenchmark_inference(engine)","metadata":{"_uuid":"945da9fd-e4d9-48a8-a997-8ab7b9f121d1","_cell_guid":"ce63e2fb-4e7d-4876-9eec-d6d268f45238","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-19T12:55:28.730868Z","iopub.status.idle":"2025-03-19T12:55:28.731112Z","shell.execute_reply":"2025-03-19T12:55:28.731004Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import HfApi\nfrom kaggle_secrets import UserSecretsClient\n\n# Lấy Hugging Face Token từ Kaggle Secrets\nuser_secrets = UserSecretsClient()\nHF_TOKEN = user_secrets.get_secret(\"HF_UPLOAD_TOKEN\")  # Cần token có quyền `Write`\n\n# Repo Dataset của bạn\nrepo_id = \"nhotin/segment-text\"  # Thay thế bằng repo của bạn\nfile_path = \"/kaggle/working/model.engine\"  # File engine đã tạo\nupload_path = \"model.engine\"  # Tên file sau khi upload lên HF\n\n# Khởi tạo API và upload file lên Hugging Face Dataset\napi = HfApi()\napi.upload_file(\n    path_or_fileobj=file_path,\n    path_in_repo=upload_path,\n    repo_id=repo_id,\n    repo_type=\"dataset\",  # Bắt buộc với dataset\n    token=HF_TOKEN\n)\n\nprint(f\"Đã upload {file_path} lên Hugging Face Dataset: {repo_id}/{upload_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T12:55:28.731850Z","iopub.status.idle":"2025-03-19T12:55:28.732093Z","shell.execute_reply":"2025-03-19T12:55:28.731997Z"}},"outputs":[],"execution_count":null}]}