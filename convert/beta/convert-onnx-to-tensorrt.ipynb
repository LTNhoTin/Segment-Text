{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import requests\n\nfile_url = \"https://huggingface.co/datasets/nhotin/segment-text/resolve/main/model.onnx\"\nfile_path = \"model.onnx\"  \nresponse = requests.get(file_url, stream=True)\nif response.status_code == 200:\n    with open(file_path, \"wb\") as f:\n        for chunk in response.iter_content(chunk_size=1024):\n            f.write(chunk)\n    print(f\"Đã tải file ONNX thành công: {file_path}\")\nelse:\n    print(f\"Lỗi khi tải file: {response.status_code}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T15:07:02.498278Z","iopub.execute_input":"2025-03-21T15:07:02.498471Z","iopub.status.idle":"2025-03-21T15:07:08.937563Z","shell.execute_reply.started":"2025-03-21T15:07:02.498452Z","shell.execute_reply":"2025-03-21T15:07:08.936705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install numpy onnx\n!pip install tensorrt==10.7.0\n!pip install pycuda","metadata":{"_uuid":"0646f729-f5bf-4414-b2a7-00a9d2eb2e22","_cell_guid":"5652b2e4-062b-4803-99f7-c0afd33a089e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-21T15:07:08.938482Z","iopub.execute_input":"2025-03-21T15:07:08.938808Z","iopub.status.idle":"2025-03-21T15:08:36.848370Z","shell.execute_reply.started":"2025-03-21T15:07:08.938774Z","shell.execute_reply":"2025-03-21T15:08:36.847277Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import onnx\nimport os\nimport tensorrt as trt\nimport pycuda.driver as cuda\nimport pycuda.autoinit\nimport time\nimport numpy as np\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"","metadata":{"_uuid":"cc21678c-b22c-4808-af36-7254293f399c","_cell_guid":"db2f48da-a4cf-4cd3-9b98-ecff817c6a3e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-21T15:08:36.849444Z","iopub.execute_input":"2025-03-21T15:08:36.849733Z","iopub.status.idle":"2025-03-21T15:08:37.520744Z","shell.execute_reply.started":"2025-03-21T15:08:36.849702Z","shell.execute_reply":"2025-03-21T15:08:37.520083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def check_tensorrt():\n    try:\n        print(f\"TensorRT version: {trt.__version__}\")\n        print(f\"CUDA version: {os.popen('nvcc --version').read().strip()}\")\n    except ModuleNotFoundError:\n        print(\"TensorRT chưa được cài\")\n\ncheck_tensorrt()","metadata":{"_uuid":"f6905140-100c-4f10-95e9-792ba97dfc9b","_cell_guid":"49878bc3-cace-44ab-ad3f-526b6eb4299b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-21T15:08:37.523077Z","iopub.execute_input":"2025-03-21T15:08:37.523515Z","iopub.status.idle":"2025-03-21T15:08:37.543409Z","shell.execute_reply.started":"2025-03-21T15:08:37.523491Z","shell.execute_reply":"2025-03-21T15:08:37.542584Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def check_onnx_model(onnx_path):\n    model = onnx.load(onnx_path)\n    print(f\"Model name: {model.graph.name}\")\n\n    for input_tensor in model.graph.input:\n        dtype = onnx.TensorProto.DataType.Name(input_tensor.type.tensor_type.elem_type)\n        print(f\"Input: {input_tensor.name}, Type: {dtype}\")\n        \n    for output_tensor in model.graph.output:\n        dtype = onnx.TensorProto.DataType.Name(output_tensor.type.tensor_type.elem_type)\n        print(f\"Output: {output_tensor.name}, Type: {dtype}\")\n\nonnx_path = \"/kaggle/working/model.onnx\"\ncheck_onnx_model(onnx_path)","metadata":{"_uuid":"a49101d0-eebd-42df-894b-fd0317d23bb9","_cell_guid":"250efd25-2431-4e5c-8e53-2e3f1c3f5b0b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-21T15:08:37.544423Z","iopub.execute_input":"2025-03-21T15:08:37.544627Z","iopub.status.idle":"2025-03-21T15:08:38.525785Z","shell.execute_reply.started":"2025-03-21T15:08:37.544610Z","shell.execute_reply":"2025-03-21T15:08:38.524832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def print_model_info(onnx_path):\n    model = onnx.load(onnx_path)\n    print(\"\\nModel Information:\")\n    print(\"=================\")\n    print(f\"Model Name: {model.graph.name}\")\n    print(\"\\nInputs:\")\n    for input in model.graph.input:\n        print(f\"- Name: {input.name}\")\n        print(f\"  Shape: {[dim.dim_value if dim.dim_value else '?' for dim in input.type.tensor_type.shape.dim]}\")\n        print(f\"  Type: {onnx.TensorProto.DataType.Name(input.type.tensor_type.elem_type)}\")\n    \n    print(\"\\nOutputs:\")\n    for output in model.graph.output:\n        print(f\"- Name: {output.name}\")\n        print(f\"  Shape: {[dim.dim_value if dim.dim_value else '?' for dim in output.type.tensor_type.shape.dim]}\")\n        print(f\"  Type: {onnx.TensorProto.DataType.Name(output.type.tensor_type.elem_type)}\")\n\ndef build_engine(onnx_file_path, engine_file_path):\n    # First, print model information\n    print_model_info(onnx_file_path)\n    \n    TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n    print(\"\\nCreating builder...\")\n    builder = trt.Builder(TRT_LOGGER)\n    \n    print(\"Creating network...\")\n    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n    \n    print(\"Creating parser...\")\n    parser = trt.OnnxParser(network, TRT_LOGGER)\n\n    # Parse ONNX model\n    print(f\"Parsing ONNX file: {onnx_file_path}\")\n    with open(onnx_file_path, 'rb') as model:\n        if not parser.parse(model.read()):\n            print('Error: Failed to parse ONNX file')\n            for error in range(parser.num_errors):\n                print(parser.get_error(error))\n            return None\n\n    print(\"Creating builder config...\")\n    config = builder.create_builder_config()\n    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)  # 1GB workspace\n    \n    # Enable FP16 mode\n    print(\"Enabling FP16 mode...\")\n    if builder.platform_has_fast_fp16:\n        config.set_flag(trt.BuilderFlag.FP16)\n    \n    # Add optimization profile with fixed shape\n    print(\"Adding optimization profile...\")\n    profile = builder.create_optimization_profile()\n    \n    # Set fixed shape (batch_size=1, sequence_length=128)\n    shape = (1, 128)\n    profile.set_shape(\"input_ids\", shape, shape, shape)\n    profile.set_shape(\"attention_mask\", shape, shape, shape)\n    config.add_optimization_profile(profile)\n    \n    # Print network information before building\n    print(\"\\nNetwork Information:\")\n    print(\"===================\")\n    print(f\"Number of layers: {network.num_layers}\")\n    print(f\"Number of inputs: {network.num_inputs}\")\n    print(f\"Number of outputs: {network.num_outputs}\")\n    for i in range(network.num_outputs):\n        output = network.get_output(i)\n        print(f\"Output {i}: {output.name}, shape={output.shape}, dtype={output.dtype}\")\n    \n    # Build and save engine\n    print(\"\\nBuilding engine...\")\n    engine = builder.build_serialized_network(network, config)\n    if engine is None:\n        print(\"Error: Failed to build TensorRT engine\")\n        return None\n\n    print(f\"Saving engine to: {engine_file_path}\")\n    with open(engine_file_path, 'wb') as f:\n        f.write(engine)\n\n    print(f\"Model converted successfully! Saved as {engine_file_path}\")\n    return engine\n\nif __name__ == \"__main__\":\n    onnx_path = \"model.onnx\"\n    engine_path = \"model.engine\"\n    print(f\"Starting conversion from {onnx_path} to {engine_path}\")\n    build_engine(onnx_path, engine_path) ","metadata":{"_uuid":"d7850156-3b08-42c1-bb2f-161c33cf32e1","_cell_guid":"bfde0c87-584c-43b5-864b-4cbc87babbdc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-21T15:09:00.844616Z","iopub.execute_input":"2025-03-21T15:09:00.844979Z","iopub.status.idle":"2025-03-21T15:09:36.759139Z","shell.execute_reply.started":"2025-03-21T15:09:00.844953Z","shell.execute_reply":"2025-03-21T15:09:36.758048Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_engine(engine_path):\n    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n        engine = runtime.deserialize_cuda_engine(f.read())\n    return engine\n\nengine = load_engine(\"model.engine\")\nprint(\"TensorRT Engine đã load thành công!\")","metadata":{"_uuid":"80fc7ed3-7582-493d-b3f6-fd9683347f5a","_cell_guid":"02beafff-6050-4386-9df4-f63060e7dd66","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-21T15:09:36.765074Z","iopub.execute_input":"2025-03-21T15:09:36.765507Z","iopub.status.idle":"2025-03-21T15:09:37.303841Z","shell.execute_reply.started":"2025-03-21T15:09:36.765468Z","shell.execute_reply":"2025-03-21T15:09:37.302813Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import HfApi\nfrom kaggle_secrets import UserSecretsClient\n\n# Lấy Hugging Face Token từ Kaggle Secrets\nuser_secrets = UserSecretsClient()\nHF_TOKEN = user_secrets.get_secret(\"HF_UPLOAD_TOKEN\")  # Cần token có quyền `Write`\n\n# Repo Dataset của bạn\nrepo_id = \"nhotin/segment-text\"  # Thay thế bằng repo của bạn\nfile_path = \"/kaggle/working/model.engine\"  # File engine đã tạo\nupload_path = \"model.engine\"  # Tên file sau khi upload lên HF\n\n# Khởi tạo API và upload file lên Hugging Face Dataset\napi = HfApi()\napi.upload_file(\n    path_or_fileobj=file_path,\n    path_in_repo=upload_path,\n    repo_id=repo_id,\n    repo_type=\"dataset\",  # Bắt buộc với dataset\n    token=HF_TOKEN\n)\n\nprint(f\"Đã upload {file_path} lên Hugging Face Dataset: {repo_id}/{upload_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T15:09:37.400983Z","iopub.execute_input":"2025-03-21T15:09:37.401338Z","iopub.status.idle":"2025-03-21T15:09:54.635358Z","shell.execute_reply.started":"2025-03-21T15:09:37.401307Z","shell.execute_reply":"2025-03-21T15:09:54.634573Z"}},"outputs":[],"execution_count":null}]}